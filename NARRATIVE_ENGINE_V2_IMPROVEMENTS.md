# ChimpNews Narrative Engine v2.0 - Mejoras Implementadas

Este documento detalla todas las mejoras implementadas para lograr videos de calidad de estudio profesional.

---

## üìã Resumen de Cambios

### ‚úÖ 1. Scene Builder Service Mejorado (`services/sceneBuilderService.ts`)

**Antes:** El servicio exist√≠a pero generaba prompts b√°sicos y no se usaba en el pipeline.

**Despu√©s:** 
- Genera prompts visuales optimizados para InfiniteTalk
- Valida y corrige autom√°ticamente los shot types seg√∫n el spec:
  - **Hook** (escena 1) ‚Üí `closeup`
  - **Conflict** ‚Üí `closeup`  
  - **Payoff** (√∫ltima escena) ‚Üí `wide`
  - **Resto** ‚Üí `medium`
- Detecta el tipo de escena bas√°ndose en la estructura narrativa
- A√±ade informaci√≥n de iluminaci√≥n seg√∫n el mood de cada escena
- Genera hints de expresi√≥n facial para cada personaje
- Soporta las 4 estructuras narrativas: `classic`, `double_conflict`, `hot_take`, `perspective_clash`

```typescript
// Ejemplo de uso
import { generateScenePrompts } from './services/sceneBuilderService';

const scenePrompts = generateScenePrompts(scriptWithScenes, config);
// Cada prompt incluye: visualPrompt, lightingMood, expressionHint, shot corregido
```

---

### ‚úÖ 2. Mapeo de Voces Simplificado (`services/openaiService.ts`)

**Antes:** Mapeo complejo con muchas voces legacy que confund√≠a.

**Despu√©s:**
- `echo` y `shimmer` se usan directamente (como dice el spec)
- Las voces legacy siguen funcionando por compatibilidad
- hostA ‚Üí `echo` (male, warm)
- hostB ‚Üí `shimmer` (female, expressive)

```typescript
// El spec dice:
// hostA (Rusty) ‚Üí voice: "echo"
// hostB (Dani) ‚Üí voice: "shimmer"

// Ahora funciona directamente sin mapeo
config.characters.hostA.voiceName = "echo";  // ‚úÖ Funciona directo
config.characters.hostB.voiceName = "shimmer"; // ‚úÖ Funciona directo
```

---

### ‚úÖ 3. Integraci√≥n de Scene Builder en InfiniteTalk (`services/geminiService.ts`)

**Antes:** Los prompts de video se generaban inline sin usar Scene Builder.

**Despu√©s:**
- `generateVideoSegmentsWithInfiniteTalk` ahora usa Scene Builder
- Los prompts visuales optimizados se pasan a cada generaci√≥n de video
- Pre-validaci√≥n de audio URLs antes de iniciar generaci√≥n
- Mejor logging con detalles de correcciones de shots
- Soporte completo para metadatos de escena v2.0

```typescript
// El flujo ahora es:
// 1. Script LLM genera scenes con video_mode, model, shot
// 2. Scene Builder valida/corrige shots y genera visualPrompts
// 3. InfiniteTalk usa los prompts optimizados para cada segmento
```

---

### ‚úÖ 4. Servicio de Composici√≥n de Video con Shotstack (`services/shotstackService.ts`) üÜï

Nuevo servicio para composici√≥n profesional de video **en la nube** - funciona con Vercel!

**¬øPor qu√© Shotstack y no FFmpeg directo?**
- ‚ö†Ô∏è Vercel es serverless ‚Üí no puede ejecutar FFmpeg
- ‚úÖ Shotstack es un API de video en la nube ("FFmpeg as a Service")
- ‚úÖ Funciona perfectamente con Vercel
- üí∞ Costo: ~$0.05 por minuto de video renderizado

**Caracter√≠sticas:**
- Renderizado en la nube (1080p, HD, 4K)
- Transiciones: `fade`, `wipeLeft`, `slideLeft`, `slideRight`, `zoom` (+ variantes Slow/Fast)
- Intro/Outro autom√°tico
- Watermark opcional
- Genera poster/thumbnail del video
- Webhooks para notificaci√≥n cuando termina

```typescript
import { composeVideoWithShotstack } from './services/geminiService';

// Despu√©s de generar todos los videos con InfiniteTalk:
const result = await composeVideoWithShotstack(
  segments,
  videoUrls,
  videos,
  config,
  {
    resolution: '1080',
    transition: 'fade',
    transitionDuration: 0.3
  }
);

if (result.success) {
  console.log('Video URL:', result.videoUrl);
  console.log('Poster URL:', result.posterUrl);
}
```

**Alternativa: `videoCompositor.ts`** (si tienes tu propio servidor con FFmpeg)

---

### ‚úÖ 5. Utilidades de Audio Mejoradas (`services/audioUtils.ts`)

**Antes:** Solo decode b√°sico.

**Despu√©s:**
- **Normalizaci√≥n de loudness** a -16 LUFS (est√°ndar para podcast/streaming)
- **True peak limiting** a -1.5 dBTP
- **Compresi√≥n din√°mica** opcional
- **Noise gate** para reducir ruido de fondo
- **High-pass filter** para eliminar rumble (80Hz default)
- **An√°lisis de audio**: RMS, Peak, LUFS aproximado
- **Export a WAV** base64

```typescript
import { processAudioSegment, normalizeAudio } from './services/audioUtils';

// Procesar un segmento completo
const result = await processAudioSegment(audioBase64, {
  normalize: true,
  targetLUFS: -16,
  applyHighPass: true,
  applyNoiseGate: false
});
// result.audioBase64 ‚Üí Audio normalizado
// result.peakDb ‚Üí Peak en dB
// result.rmsDb ‚Üí RMS en dB
```

---

### ‚úÖ 6. Migraci√≥n SQL (`supabase_narrative_engine_defaults_migration.sql`)

Nueva migraci√≥n que a√±ade:

**Campos en `productions`:**
- `narrative_used` - Tipo de narrativa usada
- `scenes` - JSONB con estructura completa de escenas
- `audio_normalized` - Flag de normalizaci√≥n
- `video_composition_url` - URL del video final compuesto
- `composition_status` - Estado del proceso de composici√≥n

**Campos en `generated_videos`:**
- `scene_metadata` - Metadatos del Scene Builder
- `lighting_mood` - Mood de iluminaci√≥n
- `shot_type` - Tipo de shot para filtrado

**Campos en `audio_cache`:**
- `normalized` - Flag de normalizaci√≥n
- `peak_db` - Peak en dB
- `rms_db` - RMS en dB

**√çndices y Vistas:**
- √çndices para queries por narrative_used, composition_status, shot_type
- Vista `narrative_analytics` para estad√≠sticas de uso
- Vista `shot_distribution` para an√°lisis de shots

---

## üé¨ Pipeline de Producci√≥n Actualizado

```
1. News Ingestion (SerpAPI)
   ‚Üì
2. Viral Hook (GPT-4o)
   ‚Üì
3. Script Generation (GPT-4o + Narrative Engine v2.0)
   ‚îÇ  - Selecci√≥n autom√°tica de narrativa
   ‚îÇ  - Generaci√≥n de scenes con metadata
   ‚Üì
4. Scene Builder (NUEVO)
   ‚îÇ  - Validaci√≥n de shot types
   ‚îÇ  - Generaci√≥n de prompts visuales
   ‚îÇ  - Hints de expresi√≥n y iluminaci√≥n
   ‚Üì
5. TTS Audio (OpenAI: echo/shimmer)
   ‚îÇ  - Normalizaci√≥n a -16 LUFS (opcional)
   ‚îÇ  - Upload a Supabase Storage
   ‚Üì
6. InfiniteTalk Video Generation
   ‚îÇ  - Usa prompts del Scene Builder
   ‚îÇ  - Metadata de escena para consistencia
   ‚Üì
7. Video Composition (NUEVO - requiere backend)
   ‚îÇ  - FFmpeg merge con transiciones
   ‚îÇ  - Normalizaci√≥n de audio
   ‚îÇ  - Output 1080p H.264
   ‚Üì
8. YouTube Upload
```

---

## üîß Configuraci√≥n Requerida

### Variables de Entorno (nuevas/actualizadas)

```env
# ============================================
# SHOTSTACK - Video Composition (RECOMENDADO)
# ============================================
# Signup: https://shotstack.io (tiene free tier para testing)
# Costo: ~$0.05 por minuto de video renderizado

VITE_SHOTSTACK_API_KEY=your_shotstack_api_key_here
VITE_SHOTSTACK_ENV=stage   # 'stage' para testing, 'v1' para producci√≥n

# ============================================
# ALTERNATIVA: Backend FFmpeg propio (opcional)
# ============================================
# Solo si tienes tu propio servidor con FFmpeg
VITE_COMPOSITION_BACKEND_URL=https://your-ffmpeg-backend.com

# ============================================
# VOCES (ya configurado por default)
# ============================================
# En channel config: hostA.voiceName = "echo", hostB.voiceName = "shimmer"
```

### Pasos para configurar Shotstack:

1. **Crear cuenta**: https://shotstack.io/register
2. **Obtener API Key**: Dashboard > API Keys
3. **Copiar la key** en tu archivo `.env.local`:
   ```env
   VITE_SHOTSTACK_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxx
   VITE_SHOTSTACK_ENV=stage
   ```
4. **Deploy en Vercel**: Las variables se agregan en Project Settings > Environment Variables

### Ejecutar Migraci√≥n SQL

```bash
# En Supabase SQL Editor o CLI
psql -f supabase_narrative_engine_defaults_migration.sql
```

---

## üìä Mejoras de Calidad

| Aspecto | Antes | Despu√©s |
|---------|-------|---------|
| Shot Types | Manual, sin validaci√≥n | Auto-corregido seg√∫n spec |
| Voces | Mapeo confuso | echo/shimmer directos |
| Prompts Visuales | Inline b√°sicos | Scene Builder optimizados |
| Audio | Sin normalizaci√≥n | -16 LUFS, peak limited |
| Video Composition | Solo browser playback | FFmpeg backend ready |
| Iluminaci√≥n | Est√°tica | Din√°mica por tipo de escena |
| Expresiones | No especificadas | Hints seg√∫n mood |

---

## üöÄ Pr√≥ximos Pasos Recomendados

1. **Implementar Backend FFmpeg**
   - Crear endpoint `/api/compose` en backend Python/Node.js
   - Usar los comandos generados por `videoCompositor.ts`

2. **Habilitar Normalizaci√≥n de Audio**
   - Descomentar llamadas a `processAudioSegment` en el flujo

3. **Configurar Seed Images Personalizadas**
   - En Admin Dashboard > Production Settings > Narrative Engine Settings
   - Personalizar prompts de seed images para cada canal

4. **Monitorear Analytics**
   - Usar vistas SQL `narrative_analytics` y `shot_distribution`
   - Ajustar preferencias de narrativa seg√∫n performance

---

## üìù Archivos Modificados

- `services/sceneBuilderService.ts` - Reescrito completamente
- `services/openaiService.ts` - Simplificado mapeo de voces
- `services/geminiService.ts` - Integraci√≥n de Scene Builder
- `services/audioUtils.ts` - A√±adida normalizaci√≥n y an√°lisis
- `services/videoCompositor.ts` - **Nuevo archivo**
- `supabase_narrative_engine_defaults_migration.sql` - Migraci√≥n SQL
